{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('../dataset/train.xlsx')\n",
    "df2 = pd.read_excel('../dataset/test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df1.copy()\n",
    "test = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sector</th>\n",
       "      <th>edu</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>field</th>\n",
       "      <th>family_rel</th>\n",
       "      <th>gender</th>\n",
       "      <th>investment_gain</th>\n",
       "      <th>investment_loss</th>\n",
       "      <th>working_hours</th>\n",
       "      <th>high_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age             sector         edu       marital_status  \\\n",
       "0   1   39          State-gov   Bachelors        Never-married   \n",
       "1   2   50   Self-emp-not-inc   Bachelors   Married-civ-spouse   \n",
       "2   3   38            Private     HS-grad             Divorced   \n",
       "3   4   53            Private        11th   Married-civ-spouse   \n",
       "4   5   28            Private   Bachelors   Married-civ-spouse   \n",
       "\n",
       "                field      family_rel   gender  investment_gain  \\\n",
       "0        Adm-clerical   Not-in-family     Male             2174   \n",
       "1     Exec-managerial         Husband     Male                0   \n",
       "2   Handlers-cleaners   Not-in-family     Male                0   \n",
       "3   Handlers-cleaners         Husband     Male                0   \n",
       "4      Prof-specialty            Wife   Female                0   \n",
       "\n",
       "   investment_loss  working_hours high_income  \n",
       "0                0             40          no  \n",
       "1                0             13          no  \n",
       "2                0             40          no  \n",
       "3                0             40          no  \n",
       "4                0             40          no  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               32561 non-null  int64 \n",
      " 1   age              32561 non-null  int64 \n",
      " 2   sector           32561 non-null  object\n",
      " 3   edu              32561 non-null  object\n",
      " 4   marital_status   32561 non-null  object\n",
      " 5   field            32561 non-null  object\n",
      " 6   family_rel       32561 non-null  object\n",
      " 7   gender           32561 non-null  object\n",
      " 8   investment_gain  32561 non-null  int64 \n",
      " 9   investment_loss  32561 non-null  int64 \n",
      " 10  working_hours    32561 non-null  int64 \n",
      " 11  high_income      32561 non-null  object\n",
      "dtypes: int64(5), object(7)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16281 entries, 0 to 16280\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               16281 non-null  int64 \n",
      " 1   age              16281 non-null  int64 \n",
      " 2   sector           16281 non-null  object\n",
      " 3   edu              16281 non-null  object\n",
      " 4   marital_status   16281 non-null  object\n",
      " 5   field            16281 non-null  object\n",
      " 6   family_rel       16281 non-null  object\n",
      " 7   gender           16281 non-null  object\n",
      " 8   investment_gain  16281 non-null  int64 \n",
      " 9   investment_loss  16281 non-null  int64 \n",
      " 10  working_hours    16281 non-null  int64 \n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare distribution of train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df, column):\n",
    "    # Create a figure with 2 subplots\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "\n",
    "    # Check if the column is numeric or categorical\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        print(f'{column} is numeric')\n",
    "        # Numeric feature: Use line chart\n",
    "        sns.histplot(df1[column], bins=30, kde=True, ax=axs, color='blue', label='train ' + column, alpha=0.5)\n",
    "\n",
    "        # Add density plots for a smooth distribution\n",
    "        sns.kdeplot(df1[column], ax=axs, color='blue', alpha=0.5)\n",
    "    else:\n",
    "        print(f'{column} is categorical')\n",
    "        # Categorical feature: Use bar chart\n",
    "        sns.countplot(x=column, data=df, ax=axs, color='blue', alpha=0.5)\n",
    "\n",
    "    # Set titles and labels\n",
    "    axs.set_title(f'df {column} Distribution')\n",
    "    axs.set_xlabel('')\n",
    "    axs.set_ylabel('Count')\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_dataframes(df1, df2):\n",
    "    \"\"\"\n",
    "    This function takes two pandas DataFrames as input and draws plots to compare\n",
    "    each feature's distribution of the two DataFrames using Seaborn. Bar charts are \n",
    "    used for categorical features, and line charts are used for numeric features.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): The first DataFrame.\n",
    "    df2 (pd.DataFrame): The second DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure that both DataFrames have the same columns\n",
    "    # if not df1.columns.equals(df2.columns):\n",
    "    #     raise ValueError(\"DataFrames must have the same columns\")\n",
    "    \n",
    "    # Loop over each column in the DataFrames\n",
    "    for column in df1.columns:\n",
    "        if column not in ['high_income', 'id']:\n",
    "            # Create a figure with 2 subplots\n",
    "            fig, axs = plt.subplots(2, 1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "            # Check if the column is numeric or categorical\n",
    "            if pd.api.types.is_numeric_dtype(df1[column]):\n",
    "                print(f'{column} is numeric')\n",
    "                # Numeric feature: Use line chart\n",
    "                sns.histplot(df1[column], bins=30, kde=True, ax=axs[0], color='blue', label='train ' + column, alpha=0.5)\n",
    "                sns.histplot(df2[column], bins=30, kde=True, ax=axs[1], color='red', label='test ' + column, alpha=0.5)\n",
    "\n",
    "                # Add density plots for a smooth distribution\n",
    "                sns.kdeplot(df1[column], ax=axs[0], color='blue', alpha=0.5)\n",
    "                sns.kdeplot(df2[column], ax=axs[1], color='red', alpha=0.5)\n",
    "            else:\n",
    "                print(f'{column} is categorical')\n",
    "                # Categorical feature: Use bar chart\n",
    "                sns.countplot(x=column, data=df1, ax=axs[0], color='blue', alpha=0.5)\n",
    "                sns.countplot(x=column, data=df2, ax=axs[1], color='red', alpha=0.5)\n",
    "\n",
    "            # Set titles and labels\n",
    "            axs[0].set_title(f'df1 {column} Distribution')\n",
    "            axs[0].set_xlabel('')\n",
    "            axs[0].set_ylabel('Count')\n",
    "            axs[1].set_title(f'df2 {column} Distribution')\n",
    "            axs[1].set_xlabel(column)\n",
    "            axs[1].set_ylabel('Count')\n",
    "\n",
    "            # Adjust layout and show the plots\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# compare_dataframes(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    if col != 'high_income':\n",
    "        train[col] = train[col].str.strip()\n",
    "        test[col] = test[col].str.strip()\n",
    "    else:\n",
    "        train[col] = train[col].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def bin_column_by_quantile(df1, column, num_bins=4, labels=None):\n",
    "    \"\"\"\n",
    "    Divides a specified column in a DataFrame into bins based on quantiles.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): The DataFrame containing the column to be binned.\n",
    "    column (str): The name of the column to be binned.\n",
    "    num_bins (int): The number of quantile-based bins to create. Default is 4 (quartiles).\n",
    "    labels (list): Optional list of labels for the bins. Must be the same length as num_bins.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with an additional column for the binned values.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df1.copy()\n",
    "    if labels is not None and len(labels) != num_bins:\n",
    "        raise ValueError(\"Length of labels must be equal to num_bins\")\n",
    "    \n",
    "    # Create the bin edges based on quantiles\n",
    "    bin_edges = pd.qcut(df[column], q=num_bins, labels=labels, retbins=True)[1]\n",
    "    \n",
    "    # Bin the column based on the calculated bin edges\n",
    "    binned_column = pd.cut(df[column], bins=bin_edges, labels=labels, include_lowest=True)\n",
    "    \n",
    "    # Create a new column name for the binned values\n",
    "    binned_column_name = column + '_binned'\n",
    "    \n",
    "    # Add the binned column to the DataFrame\n",
    "    df[binned_column_name] = binned_column\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = bin_column_by_quantile(train, 'age', num_bins=4, labels=[1, 2, 3, 4])\n",
    "# test = bin_column_by_quantile(test, 'age', num_bins=4, labels=[1, 2, 3, 4])\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_column_by_custom_quantiles(df, column, quantiles=[0.25, 0.75], labels=None):\n",
    "    \"\"\"\n",
    "    Divides a specified column in a DataFrame into bins based on custom quantiles.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the column to be binned.\n",
    "    column (str): The name of the column to be binned.\n",
    "    quantiles (list): A list of quantiles to use for binning. Default is [0.25, 0.75].\n",
    "    labels (list): Optional list of labels for the bins. Must be one less than the length of quantiles + 1.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with an additional column for the binned values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the quantile values\n",
    "    quantile_values = df[column].quantile(quantiles).tolist()\n",
    "    \n",
    "    # Define the bin edges\n",
    "    bins = [-float('inf')] + quantile_values + [float('inf')]\n",
    "    \n",
    "    # If labels are not provided, create default labels\n",
    "    if labels is None:\n",
    "        labels = [i+1 for i in range(len(bins) - 1)]\n",
    "    \n",
    "    # Ensure the number of labels matches the number of bins\n",
    "    if len(labels) != len(bins) - 1:\n",
    "        raise ValueError(\"The number of labels must be one less than the number of bins\")\n",
    "    \n",
    "    # Bin the column based on the calculated bin edges\n",
    "    binned_column = pd.cut(df[column], bins=bins, labels=labels, include_lowest=True)\n",
    "    \n",
    "    # Create a new column name for the binned values\n",
    "    binned_column_name = column + '_binned'\n",
    "    \n",
    "    # Add the binned column to the DataFrame\n",
    "    df[binned_column_name] = binned_column\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = bin_column_by_custom_quantiles(train, 'age', quantiles=[0.25, 0.75])\n",
    "test = bin_column_by_custom_quantiles(test, 'age', quantiles=[0.25, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edu\n",
       "HS-grad         10501\n",
       "Some-college     7291\n",
       "Bachelors        5355\n",
       "Masters          1723\n",
       "Assoc-voc        1382\n",
       "11th             1175\n",
       "Assoc-acdm       1067\n",
       "10th              933\n",
       "7th-8th           646\n",
       "Prof-school       576\n",
       "9th               514\n",
       "12th              433\n",
       "Doctorate         413\n",
       "5th-6th           333\n",
       "1st-4th           168\n",
       "Preschool          51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['edu'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_edu(status):\n",
    "    status_stripped = str(status).strip()\n",
    "    if status_stripped in ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th', 'HS-grad']:\n",
    "        return 'undergrad'\n",
    "    elif status_stripped in ['Some-college', 'Bachelors', 'Masters', 'Assoc-voc', 'Assoc-acdm', 'Prof-school', 'Doctorate']:\n",
    "        return 'grad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['edu_new'] = train['edu'].apply(convert_edu)\n",
    "test['edu_new'] = test['edu'].apply(convert_edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### marital_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_marital_status(status):\n",
    "    status_stripped = status.strip()\n",
    "\n",
    "    if status_stripped in ['Married-civ-spouse', 'Married-spouse-absent', 'Married-AF-spouse']:\n",
    "        return 'married'\n",
    "    elif status_stripped in ['Never-married', 'Separated', 'Widowed']:\n",
    "        return 'single'\n",
    "    elif status_stripped == 'Divorced':\n",
    "        return 'divorced'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "train['marital_status_new'] = train['marital_status'].apply(convert_marital_status)\n",
    "test['marital_status_new'] = test['marital_status'].apply(convert_marital_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### high_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_mapping = {'no': 0, 'yes': 1}\n",
    "train['high_income'] = train['high_income'].map(income_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_categorical(df, column):\n",
    "    df[column] = df[column].replace('?', np.nan)\n",
    "\n",
    "    if df[column].notna().all():\n",
    "        return df\n",
    "\n",
    "    known = df[df[column].notna()]\n",
    "    unknown = df[df[column].isna()]\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    known[column] = le.fit_transform(known[column])\n",
    "    X_known = known.drop(column, axis=1)\n",
    "    y_known = known[column]\n",
    "\n",
    "    categorical_cols = X_known.select_dtypes(include=['object']).columns\n",
    "\n",
    "    le_cat = preprocessing.LabelEncoder()\n",
    "    X_known[categorical_cols] = X_known[categorical_cols].apply(lambda col: le_cat.fit_transform(col.astype(str)))\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_known, y_known)\n",
    "\n",
    "    X_unknown = unknown.drop(column, axis=1)\n",
    "\n",
    "    X_unknown[categorical_cols] = X_unknown[categorical_cols].apply(lambda col: le_cat.fit_transform(col.astype(str)))\n",
    "\n",
    "    unknown[column] = clf.predict(X_unknown)\n",
    "\n",
    "    df = pd.concat([known, unknown], axis=0)\n",
    "\n",
    "    df[column] = le.inverse_transform(df[column])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop(columns=['sector', 'edu', 'marital_status', 'high_income'], inplace=True)\n",
    "# test.drop(columns=['sector', 'edu', 'marital_status'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train.drop('target', axis=1)\n",
    "# y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = fill_missing_categorical(X, 'field')\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = fill_missing_categorical(test, 'field')\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('high_income', axis=1)\n",
    "y = train['high_income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encode_datasets(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Perform label encoding on categorical features in both train and test datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    train_df (pd.DataFrame): Training dataset\n",
    "    test_df (pd.DataFrame): Testing dataset\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: Label encoded train and test datasets\n",
    "    \"\"\"\n",
    "    # Initialize the label encoder\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # Concatenate train and test data to ensure consistency in encoding\n",
    "    combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "    \n",
    "    # Identify categorical columns\n",
    "    categorical_cols = combined_df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Label encode each categorical column\n",
    "    for col in categorical_cols:\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        combined_df[col] = label_encoders[col].fit_transform(combined_df[col])\n",
    "    \n",
    "    # Split the combined dataframe back into train and test sets\n",
    "    train_encoded = combined_df.iloc[:len(train_df), :].reset_index(drop=True)\n",
    "    test_encoded = combined_df.iloc[len(train_df):, :].reset_index(drop=True)\n",
    "    \n",
    "    return train_encoded, test_encoded\n",
    "\n",
    "\n",
    "X_encoded, test_encoded = label_encode_datasets(X, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, trial, x, y):\n",
    "    preds = model.predict(x)\n",
    "    pred_labels = (preds > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y, pred_labels)\n",
    "    f1 = f1_score(y, pred_labels)\n",
    "    precision = precision_score(y, pred_labels)\n",
    "    recall = recall_score(y, pred_labels)\n",
    "    auc = roc_auc_score(y, preds)\n",
    "\n",
    "    print(f\"Trial {trial.number} - Accuracy: {accuracy}, F1: {f1}, Precision: {precision}, Recall: {recall}, AUC: {auc}\")\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 11:08:57,651] A new study created in memory with name: no-name-3c417460-e81a-4c81-b4c2-54f2715d084d\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-06-26 11:09:22,445] Trial 0 finished with value: 0.5325678363781849 and parameters: {'lambda_l1': 1.6160707961089504, 'lambda_l2': 0.0012119035237000333, 'num_leaves': 250, 'feature_fraction': 0.8, 'bagging_fraction': 0.9, 'bagging_freq': 4, 'min_child_samples': 61, 'n_estimators': 10000, 'learning_rate': 0.25549125973737946, 'max_depth': 10, 'min_data_in_leaf': 8500, 'max_bin': 236, 'min_gain_to_split': 14.732586895110561}. Best is trial 0 with value: 0.5325678363781849.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Trial 0 - Accuracy: 0.8148628793797513, F1: 0.532219491908169, Precision: 0.6796278895300244, Recall: 0.43738070431424597, AUC: 0.8365825655489548\n",
      "VALID: Trial 0 - Accuracy: 0.8150240626288531, F1: 0.5325678363781849, Precision: 0.6802632000259283, Recall: 0.4375715391319052, AUC: 0.8364786903050907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-06-26 11:09:49,642] Trial 1 finished with value: 0.0 and parameters: {'lambda_l1': 8.99814820161787e-08, 'lambda_l2': 0.0005751742120929792, 'num_leaves': 690, 'feature_fraction': 0.9, 'bagging_fraction': 0.5, 'bagging_freq': 7, 'min_child_samples': 27, 'n_estimators': 10000, 'learning_rate': 0.20611917194088694, 'max_depth': 7, 'min_data_in_leaf': 9300, 'max_bin': 245, 'min_gain_to_split': 9.96303448560293}. Best is trial 0 with value: 0.5325678363781849.\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Trial 1 - Accuracy: 0.7591904427329972, F1: 0.0, Precision: 0.0, Recall: 0.0, AUC: 0.5\n",
      "VALID: Trial 1 - Accuracy: 0.7591904454179904, F1: 0.0, Precision: 0.0, Recall: 0.0, AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-06-26 11:10:11,619] Trial 2 finished with value: 0.5739451900046649 and parameters: {'lambda_l1': 0.00023896216042692376, 'lambda_l2': 0.03508343508897475, 'num_leaves': 710, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 4, 'min_child_samples': 74, 'n_estimators': 10000, 'learning_rate': 0.2632046868669024, 'max_depth': 3, 'min_data_in_leaf': 4600, 'max_bin': 204, 'min_gain_to_split': 7.523091577682911}. Best is trial 2 with value: 0.5739451900046649.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Trial 2 - Accuracy: 0.8228709176822587, F1: 0.5734851647760743, Precision: 0.6824773672828323, Recall: 0.49454792079433396, AUC: 0.8653498732031627\n",
      "VALID: Trial 2 - Accuracy: 0.8229476314805655, F1: 0.5739451900046649, Precision: 0.6828406446831298, Recall: 0.49521752773767247, AUC: 0.8641468063919415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-06-26 11:10:36,359] Trial 3 finished with value: 0.0 and parameters: {'lambda_l1': 0.0001131188982222881, 'lambda_l2': 0.01927634715755426, 'num_leaves': 630, 'feature_fraction': 0.7000000000000001, 'bagging_fraction': 0.5, 'bagging_freq': 6, 'min_child_samples': 58, 'n_estimators': 10000, 'learning_rate': 0.10281376828308243, 'max_depth': 8, 'min_data_in_leaf': 6100, 'max_bin': 230, 'min_gain_to_split': 11.580761948195835}. Best is trial 2 with value: 0.5739451900046649.\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Trial 3 - Accuracy: 0.7591904427329972, F1: 0.0, Precision: 0.0, Recall: 0.0, AUC: 0.6564201866974615\n",
      "VALID: Trial 3 - Accuracy: 0.7591904454179904, F1: 0.0, Precision: 0.0, Recall: 0.0, AUC: 0.6562086676084908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-06-26 11:10:59,731] Trial 4 finished with value: 0.5753052388422857 and parameters: {'lambda_l1': 1.2875667118793328e-07, 'lambda_l2': 1.2553908008237916e-05, 'num_leaves': 230, 'feature_fraction': 1.0, 'bagging_fraction': 0.7000000000000001, 'bagging_freq': 2, 'min_child_samples': 72, 'n_estimators': 10000, 'learning_rate': 0.21619543554169418, 'max_depth': 11, 'min_data_in_leaf': 3600, 'max_bin': 224, 'min_gain_to_split': 6.695096501973125}. Best is trial 4 with value: 0.5753052388422857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Trial 4 - Accuracy: 0.8244218550906188, F1: 0.5745526732661906, Precision: 0.6897716490491608, Recall: 0.4923798686141123, AUC: 0.8693373263163189\n",
      "VALID: Trial 4 - Accuracy: 0.824698222153312, F1: 0.5753052388422857, Precision: 0.6906084431565711, Recall: 0.49304916039073376, AUC: 0.8681902085290979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-06-26 11:11:23,893] Trial 5 finished with value: 0.5578609716279983 and parameters: {'lambda_l1': 0.07307135332452196, 'lambda_l2': 0.353445052499739, 'num_leaves': 770, 'feature_fraction': 0.7000000000000001, 'bagging_fraction': 0.9, 'bagging_freq': 2, 'min_child_samples': 92, 'n_estimators': 10000, 'learning_rate': 0.13243335060188077, 'max_depth': 5, 'min_data_in_leaf': 7800, 'max_bin': 231, 'min_gain_to_split': 11.059160295809747}. Best is trial 4 with value: 0.5753052388422857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Trial 5 - Accuracy: 0.8157995832697835, F1: 0.557405209713697, Precision: 0.6614032546073734, Recall: 0.4816989702385019, AUC: 0.8479521335442357\n",
      "VALID: Trial 5 - Accuracy: 0.8160990577906745, F1: 0.5578609716279983, Precision: 0.6625074225920609, Recall: 0.4818268655454533, AUC: 0.8474076029191782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-06-26 11:11:43,687] Trial 6 finished with value: 0.6887067623554822 and parameters: {'lambda_l1': 3.0199306436369528e-05, 'lambda_l2': 1.957323049032535e-06, 'num_leaves': 130, 'feature_fraction': 0.4, 'bagging_fraction': 0.5, 'bagging_freq': 7, 'min_child_samples': 37, 'n_estimators': 10000, 'learning_rate': 0.25063639830689005, 'max_depth': 9, 'min_data_in_leaf': 300, 'max_bin': 254, 'min_gain_to_split': 1.6625594560954986}. Best is trial 6 with value: 0.6887067623554822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Trial 6 - Accuracy: 0.8656675181497391, F1: 0.6927226949999803, Precision: 0.7711533274593114, Recall: 0.628842268614763, AUC: 0.9227793208818476\n",
      "VALID: Trial 6 - Accuracy: 0.8639168742462155, F1: 0.6887067623554822, Precision: 0.7667057827797821, Recall: 0.6251747831063591, AUC: 0.9187605576421924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-06-26 11:12:06,551] Trial 7 finished with value: 0.657764626815578 and parameters: {'lambda_l1': 0.0016754851405061805, 'lambda_l2': 0.00023417369384550038, 'num_leaves': 830, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'min_child_samples': 26, 'n_estimators': 10000, 'learning_rate': 0.16412135406107692, 'max_depth': 9, 'min_data_in_leaf': 1700, 'max_bin': 240, 'min_gain_to_split': 1.6640949545454382}. Best is trial 6 with value: 0.6887067623554822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Trial 7 - Accuracy: 0.8510795099657675, F1: 0.6579369714615589, Precision: 0.7361920002552398, Recall: 0.5947585944947085, AUC: 0.909209824753364\n",
      "VALID: Trial 7 - Accuracy: 0.8510794608099997, F1: 0.657764626815578, Precision: 0.7364833276790861, Recall: 0.5943114195965193, AUC: 0.9067115304329763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-06-26 11:12:28,413] Trial 8 finished with value: 0.5687964591184804 and parameters: {'lambda_l1': 3.455343059962194e-05, 'lambda_l2': 0.03370999458863373, 'num_leaves': 910, 'feature_fraction': 0.7000000000000001, 'bagging_fraction': 1.0, 'bagging_freq': 3, 'min_child_samples': 57, 'n_estimators': 10000, 'learning_rate': 0.1916808702204079, 'max_depth': 12, 'min_data_in_leaf': 6700, 'max_bin': 207, 'min_gain_to_split': 7.077471747895751}. Best is trial 6 with value: 0.6887067623554822.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Trial 8 - Accuracy: 0.8219265380176068, F1: 0.5681104739764568, Precision: 0.6829384684816954, Recall: 0.48635386573328515, AUC: 0.8605496217863922\n",
      "VALID: Trial 8 - Accuracy: 0.8222105684680535, F1: 0.5687964591184804, Precision: 0.6839208541306154, Recall: 0.4869288250673118, AUC: 0.8599239636446377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-06-26 11:12:53,760] Trial 9 finished with value: 0.0 and parameters: {'lambda_l1': 9.653496826456538, 'lambda_l2': 1.267590266659084e-08, 'num_leaves': 150, 'feature_fraction': 1.0, 'bagging_fraction': 0.4, 'bagging_freq': 7, 'min_child_samples': 97, 'n_estimators': 10000, 'learning_rate': 0.2078560625432853, 'max_depth': 7, 'min_data_in_leaf': 9200, 'max_bin': 239, 'min_gain_to_split': 4.665404978924494}. Best is trial 6 with value: 0.6887067623554822.\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [50, 1000] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 990].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.2, 0.95] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.2, 0.9].\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"feature_fraction\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': 0.1, 'low': 0.4, 'high': 1.0, 'log': False}\n",
      "  warnings.warn(\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Trial 9 - Accuracy: 0.7591904427329972, F1: 0.0, Precision: 0.0, Recall: 0.0, AUC: 0.5\n",
      "VALID: Trial 9 - Accuracy: 0.7591904454179904, F1: 0.0, Precision: 0.0, Recall: 0.0, AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/kieusontung/Library/CloudStorage/OneDrive-Personal/Code/MidTerm/.venv/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define the hyperparameters to be tuned\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbose': -1,\n",
    "        'feature_pre_filter': False,\n",
    "        'n_jobs': -1,\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 50, 1000, step=20),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0, step=0.1),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0, step=0.1),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    acc_train, f1_train, prec_train, recall_train, auc_train = [], [], [], [], []\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    aucs = []\n",
    "    \n",
    "    # Perform Stratified K-Fold cross-validation\n",
    "    for train_index, valid_index in skf.split(X_encoded, y):\n",
    "        train_x, valid_x = X_encoded.iloc[train_index], X_encoded.iloc[valid_index]\n",
    "        train_y, valid_y = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        # Train the model\n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "        gbm = lgb.train(param, dtrain, valid_sets=[dvalid])\n",
    "\n",
    "        # Predict and evaluate on trainset\n",
    "        preds = gbm.predict(train_x)\n",
    "        pred_labels = (preds > 0.5).astype(int)\n",
    "        \n",
    "        acc_train.append(accuracy_score(train_y, pred_labels))\n",
    "        f1_train.append(f1_score(train_y, pred_labels))\n",
    "        prec_train.append(precision_score(train_y, pred_labels))\n",
    "        recall_train.append(recall_score(train_y, pred_labels))\n",
    "        auc_train.append(roc_auc_score(train_y, preds))\n",
    "        \n",
    "        # Predict and evaluate on validset\n",
    "        preds = gbm.predict(valid_x)\n",
    "        pred_labels = (preds > 0.5).astype(int)\n",
    "        \n",
    "        accuracies.append(accuracy_score(valid_y, pred_labels))\n",
    "        f1_scores.append(f1_score(valid_y, pred_labels))\n",
    "        precisions.append(precision_score(valid_y, pred_labels))\n",
    "        recalls.append(recall_score(valid_y, pred_labels))\n",
    "        aucs.append(roc_auc_score(valid_y, preds))\n",
    "    \n",
    "    # Calculate mean of the metrics\n",
    "    mean_accuracy = np.mean(acc_train)\n",
    "    mean_f1 = np.mean(f1_train)\n",
    "    mean_precision = np.mean(prec_train)\n",
    "    mean_recall = np.mean(recall_train)\n",
    "    mean_auc = np.mean(auc_train)\n",
    "\n",
    "    print(f\"TRAIN: Trial {trial.number} - Accuracy: {mean_accuracy}, F1: {mean_f1}, Precision: {mean_precision}, Recall: {mean_recall}, AUC: {mean_auc}\")\n",
    "    \n",
    "    # Calculate mean of the metrics\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_auc = np.mean(aucs)\n",
    "    \n",
    "    # Print mean metrics for this trial\n",
    "    print(f\"VALID: Trial {trial.number} - Accuracy: {mean_accuracy}, F1: {mean_f1}, Precision: {mean_precision}, Recall: {mean_recall}, AUC: {mean_auc}\")\n",
    "    \n",
    "    # Return a single metric (mean accuracy in this case) for optimization\n",
    "    return mean_f1\n",
    "\n",
    "# Create the study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(trial.value))\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
